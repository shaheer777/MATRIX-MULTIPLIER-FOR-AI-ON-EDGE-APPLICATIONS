Neural networks, particularly deep learning algorithms, have become increasingly popular
in recent years due to their ability to achieve high accuracy in tasks such as image
recognition, natural language processing, and speech recognition. However, the
computational demands of these algorithms can be significant, and traditional processors
such as CPUs and GPUs may not be able to meet the performance and power requirements
of these applications. This has led to the development of AI accelerators, specialized
hardware devices that are optimized for the computation-intensive tasks required by neural
networks. These accelerators can improve performance, reduce power consumption and
make AI more accessible to edge devices, embedded systems, and other resource-
constrained environments. This thesis proposes a Matrix Multiplier based on Systolic
Array parallel computation with hybrid Modified Booth Wallace tree multiplier as
processing element for AI on edge applications that enhances computational speed while
reducing area and power consumption. The design and verification of Processing Unit and
Processing Element has been done using Hardware Description Language (HDL) Verilog
Language. The tool used for Compilation, Elaboration and Simulation of RTL code is
Cadence Xcelium. The Synthesis has been done in Open Source Tool Yosys for PICO
Tapeout submission.

Designed and owned by Engr.Shaheer Ashraf

